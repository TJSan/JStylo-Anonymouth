============================ JStylo Analysis Output ============================
Started analysis on 2013-03-22, 17:43:13
Running 10-folds cross validation on training corpus

Training corpus:
> cc (18 documents)
> g (16 documents)
> h (18 documents)
> r (14 documents)
> ww (15 documents)

Feature set: 9 feature-set:
> Unique Words Count
> Complexity
> Sentence Count
> Average Sentence Length
> Average Syllables in Word
> Gunning-Fog Readability Index
> Character Space
> Letter Space
> Flesch Reading Ease Score

Classifiers used:
> weka.classifiers.functions.SMO                    	-C 1.0 -L 0.0010 -P 1.0E-12 -N 0 -V -1 -W 1 -K weka.classifiers.functions.supportVector.PolyKernel -C 250007 -E 1.0 

================================================================================

2013-03-22, 17:43:13 Extracting features from training corpus (using sparse representation)...
2013-03-22, 17:43:14 done!

Training corpus features (ARFF):
================================
@relation JStylo

@attribute 'Unique-Words-Count{-}' numeric
@attribute 'Complexity{-}' numeric
@attribute 'Sentence-Count{-}' numeric
@attribute 'Average-Sentence-Length{-}' numeric
@attribute 'Average-Syllables-in-Word{-}' numeric
@attribute 'Gunning-Fog-Readability-Index{-}' numeric
@attribute 'Character-Space{-}' numeric
@attribute 'Letter-Space{-}' numeric
@attribute 'Flesch-Reading-Ease-Score{-}' numeric
@attribute authorName {cc,g,h,r,ww}

@data
{0 260,1 0.536082,2 14,3 34.642857,4 1.701031,5 20.455081,6 2940,7 2344,8 27.765284}
{0 271,1 0.550813,2 14,3 35.142857,4 1.745935,5 21.455517,6 3051,7 2440,8 23.458902}
{0 265,1 0.528942,2 19,3 26.368421,4 1.778443,5 18.930602,6 3063,7 2468,8 29.614765}
{0 276,1 0.541176,2 19,3 26.842105,4 1.684314,5 17.874097,6 3070,7 2464,8 37.097322}
{0 271,1 0.548583,2 16,3 30.875,4 1.728745,5 20.690081,6 2972,7 2361,8 29.245053}
{0 248,1 0.506122,2 15,3 32.666667,4 1.804082,5 22.454422,6 3004,7 2418,8 21.053027}
{0 302,1 0.618852,2 19,3 25.684211,4 1.883197,5 19.617947,6 3130,7 2542,8 21.447084}
{0 274,1 0.540434,2 19,3 26.684211,4 1.830375,5 19.352185,6 3158,7 2528,8 24.900822}
{0 284,1 0.589212,2 14,3 34.428571,4 1.759336,5 21.904209,6 2978,7 2356,8 23.050166}
{0 279,1 0.559118,2 15,3 33.266667,4 1.805611,5 23.086226,6 3098,7 2476,8 20.314624}
{0 270,1 0.54878,2 16,3 30.75,4 1.739837,5 19.535772,6 2981,7 2375,8 28.433506}
{0 280,1 0.56,2 16,3 31.25,4 1.862,5 22.42,6 3127,7 2523,8 17.59105}
{0 280,1 0.543689,2 18,3 28.611111,4 1.751456,5 19.444444,6 3105,7 2515,8 29.621518}
{0 256,1 0.515091,2 20,3 24.85,4 1.742455,5 18.149256,6 2952,7 2379,8 34.20058}
{0 274,1 0.558045,2 19,3 25.842105,4 1.788187,5 19.298146,6 3020,7 2446,8 29.324611}
{0 259,1 0.526423,2 13,3 37.846154,4 1.723577,5 22.94334,6 2988,7 2401,8 22.60652}
{0 240,1 0.494845,2 15,3 32.333333,4 1.754639,5 20.685911,6 2947,7 2393,8 25.574192}
{0 256,1 0.52459,2 19,3 25.684211,4 1.811475,5 19.781881,6 3064,7 2473,8 27.514707}
{0 234,1 0.488518,2 20,3 23.95,4 1.676409,5 15.258497,6 2944,7 2208,8 40.701533,9 g}
{0 261,1 0.538144,2 18,3 26.944444,4 1.54433,5 15.31386,6 2957,7 2132,8 48.83608,9 g}
{0 244,1 0.48996,2 15,3 33.2,4 1.60241,5 18.982811,6 3018,7 2271,8 37.573145,9 g}
{0 245,1 0.49,2 46,3 10.869565,4 1.526,5 9.787826,6 2892,7 2006,8 66.702791,9 g}
{0 235,1 0.5,2 43,3 10.930233,4 1.634043,5 11.606136,6 2832,7 2038,8 57.500814,9 g}
{0 219,1 0.438,2 17,3 29.411765,4 1.65,5 18.404706,6 2890,7 2311,8 37.392059,9 g}
{0 231,1 0.478261,2 22,3 21.954545,4 1.68323,5 16.31805,6 2833,7 2219,8 42.149894,9 g}
{0 224,1 0.452525,2 27,3 18.333333,4 1.587879,5 12.424242,6 2845,7 2236,8 53.892121,9 g}
{0 243,1 0.476471,2 19,3 26.842105,4 1.684314,5 19.128999,6 3080,7 2480,8 37.097322,9 g}
{0 260,1 0.516899,2 20,3 25.15,4 1.73161,5 18.807515,6 3023,7 2435,8 34.813515,9 g}
{0 257,1 0.520243,2 36,3 13.722222,4 1.532389,5 10.266217,6 2812,7 2245,8 63.266863,9 g}
{0 267,1 0.530815,2 37,3 13.594595,4 1.467197,5 9.493504,6 2749,7 2158,8 68.911636,9 g}
{0 253,1 0.517382,2 39,3 12.538462,4 1.443763,5 8.532767,6 2633,7 2072,8 71.96613,9 g}
{0 251,1 0.499006,2 32,3 15.71875,4 1.379722,5 8.673186,6 2643,7 2075,8 74.156015,9 g}
{0 237,1 0.477823,2 35,3 14.171429,4 1.461694,5 9.539539,6 2701,7 2124,8 68.791726,9 g}
{0 224,1 0.475584,2 18,3 26.166667,4 1.619958,5 15.222505,6 2702,7 2158,8 43.227426,9 g}
{0 254,1 0.513131,2 24,3 20.625,4 1.840404,5 16.977273,6 3169,7 2572,8 30.202443,9 h}
{0 264,1 0.532258,2 21,3 23.619048,4 1.97379,5 21.302458,6 3352,7 2761,8 15.879005,9 h}
{0 217,1 0.460722,2 27,3 17.444444,4 1.963907,5 18.782449,6 3039,7 2456,8 22.982392,9 h}
{0 240,1 0.48583,2 20,3 24.7,4 1.917004,5 20.244372,6 3193,7 2591,8 19.585957,9 h}
{0 222,1 0.439604,2 20,3 25.25,4 1.809901,5 18.020792,6 3086,7 2507,8 28.088626,9 h}
{0 253,1 0.515275,2 19,3 25.842105,4 1.863544,5 20.438675,6 3125,7 2548,8 22.949459,9 h}
{0 225,1 0.453629,2 19,3 26.105263,4 1.762097,5 18.506621,6 2984,7 2404,8 31.264771,9 h}
{0 259,1 0.524291,2 23,3 21.478261,4 1.923077,5 19.198592,6 3199,7 2615,8 22.342258,9 h}
{0 256,1 0.510978,2 22,3 22.772727,4 1.912176,5 19.727853,6 3223,7 2562,8 21.950622,9 h}
{0 248,1 0.505092,2 25,3 19.64,4 2.081466,5 21.460888,6 3390,7 2749,8 10.808343,9 h}
{0 259,1 0.519038,2 19,3 26.263158,4 1.861723,5 20.284822,6 3249,7 2642,8 22.676091,9 h}
{0 251,1 0.510163,2 24,3 20.5,4 1.737805,5 15.110569,6 3032,7 2355,8 39.009207,9 h}
{0 263,1 0.516699,2 22,3 23.136364,4 1.80943,5 18.52763,6 3258,7 2606,8 30.273791,9 h}
{0 244,1 0.495935,2 20,3 24.6,4 1.825203,5 19.84,6 3054,7 2469,8 27.453805,9 h}
{0 235,1 0.47,2 23,3 21.73913,4 1.796,5 17.815652,6 3046,7 2470,8 32.828183,9 h}
{0 249,1 0.492095,2 19,3 26.631579,4 1.824111,5 19.269232,6 3200,7 2584,8 25.484185,9 h}
{0 246,1 0.495968,2 27,3 18.37037,4 1.895161,5 17.348148,6 3258,7 2653,8 27.858429,9 h}
{0 261,1 0.509766,2 23,3 22.26087,4 1.8125,5 17.732473,6 3251,7 2645,8 30.902717,9 h}
{0 250,1 0.498008,2 31,3 16.193548,4 1.49004,5 10.700527,6 2769,7 2171,8 64.341178,9 r}
{0 230,1 0.470348,2 36,3 13.583333,4 1.355828,5 8.05092,6 2488,7 1916,8 78.344849,9 r}
{0 241,1 0.484909,2 34,3 14.617647,4 1.39839,5 8.824926,6 2652,7 2064,8 73.694265,9 r}
{0 280,1 0.576132,2 34,3 14.294118,4 1.479424,5 9.009828,6 2838,7 2119,8 67.167211,9 r}
{0 280,1 0.583333,2 35,3 13.714286,4 1.5125,5 9.319048,6 2829,7 2122,8 64.9575,9 r}
{0 242,1 0.512712,2 30,3 15.733333,4 1.413136,5 9.089944,6 2648,7 1997,8 71.314395,9 r}
{0 215,1 0.444215,2 24,3 20.166667,4 1.582645,5 13.190634,6 2632,7 2044,8 52.474098,9 r}
{0 227,1 0.474895,2 24,3 19.916667,4 1.554393,5 12.820223,6 2528,7 1933,8 55.11791,9 r}
{0 251,1 0.499006,2 28,3 17.964286,4 1.379722,5 10.525675,6 2622,7 1999,8 71.876797,9 r}
{0 253,1 0.517382,2 31,3 15.774194,4 1.423313,5 9.499861,6 2568,7 1975,8 70.411924,9 r}
{0 258,1 0.525458,2 36,3 13.638889,4 1.419552,5 8.714211,6 2662,7 2024,8 72.897434,9 r}
{0 238,1 0.485714,2 26,3 18.846154,4 1.418367,5 10.55887,6 2691,7 2073,8 67.712276,9 r}
{0 250,1 0.505051,2 35,3 14.142857,4 1.428283,5 8.647042,6 2723,7 2063,8 71.647273,9 r}
{0 239,1 0.478958,2 41,3 12.170732,4 1.42485,5 7.593744,6 2722,7 2025,8 73.939423,9 r}
{0 260,1 0.525253,2 24,3 20.625,4 1.60404,5 14.310606,6 2928,7 2321,8 50.198807,9 ww}
{0 249,1 0.502016,2 28,3 17.714286,4 1.554435,5 11.601843,6 2871,7 2250,8 57.349758,9 ww}
{0 247,1 0.509278,2 25,3 19.4,4 1.546392,5 12.625979,6 2768,7 2176,8 56.319258,9 ww}
{0 246,1 0.5125,2 24,3 20,4 1.635417,5 14.166667,6 2815,7 2236,8 48.17875,9 ww}
{0 204,1 0.409639,2 25,3 19.92,4 1.819277,5 17.526233,6 3032,7 2426,8 32.705357,9 ww}
{0 228,1 0.469136,2 30,3 16.2,4 1.757202,5 14.29893,6 2984,7 2402,8 41.732741,9 ww}
{0 251,1 0.508097,2 32,3 15.4375,4 1.740891,5 13.705364,6 2962,7 2361,8 43.886585,9 ww}
{0 244,1 0.480315,2 30,3 16.933333,4 1.677165,5 13.544987,6 3056,7 2447,8 47.759478,9 ww}
{0 214,1 0.447699,2 32,3 14.9375,4 1.648536,5 10.744874,6 2756,7 2145,8 52.207329,9 ww}
{0 260,1 0.534979,2 28,3 17.357143,4 1.853909,5 17.313228,6 3046,7 2463,8 32.376759,9 ww}
{0 253,1 0.50099,2 25,3 20.2,4 1.867327,5 18.535446,6 3144,7 2563,8 28.356158,9 ww}
{0 247,1 0.488142,2 27,3 18.740741,4 1.966403,5 20.223569,6 3268,7 2680,8 21.455441,9 ww}
{0 226,1 0.45935,2 30,3 16.4,4 1.823171,5 15.58439,6 3160,7 2523,8 35.948756,9 ww}
{0 225,1 0.461066,2 27,3 18.074074,4 1.766393,5 15.508318,6 3007,7 2387,8 39.05293,9 ww}

Calculating InfoGain on the training set's features
===================================================
Features InfoGain score (non-zero only):
----------------------------------------
> Letter-Space{-}                    1.119713
> Average-Sentence-Length{-}         1.003393
> Sentence-Count{-}                  0.965165
> Flesch-Reading-Ease-Score{-}       0.936281
> Average-Syllables-in-Word{-}       0.871930
> Character-Space{-}                 0.840736
> Gunning-Fog-Readability-Index{-}   0.821703
> Unique-Words-Count{-}              0.319796
> Complexity{-}                      0.319796

Feature-type breakdown:
-----------------------
> Sentence-Count                  0.965165 (13.41%)
> Letter-Space                    1.119713 (15.55%)
> Unique-Words-Count              0.319796 (4.44%)
> Complexity                      0.319796 (4.44%)
> Average-Syllables-in-Word       0.871930 (12.11%)
> Gunning-Fog-Readability-Index   0.821703 (11.41%)
> Average-Sentence-Length         1.003393 (13.94%)
> Flesch-Reading-Ease-Score       0.936281 (13.01%)
> Character-Space                 0.840736 (11.68%)

done!

2013-03-22, 17:43:14 Starting 10-folds cross-validation on training corpus phase...

================================================================================

Running analysis with classifier 1 out of 1:
> Classifier: weka.classifiers.functions.SMO
> Options:    -C 1.0 -L 0.0010 -P 1.0E-12 -N 0 -V -1 -W 1 -K weka.classifiers.functions.supportVector.PolyKernel -C 250007 -E 1.0 

2013-03-22, 17:43:14 Starting cross validation...
2013-03-22, 17:43:15 done!

=== Summary ===

Correctly Classified Instances          57               71.25   %
Incorrectly Classified Instances        23               28.75   %
Kappa statistic                          0.6386
Mean absolute error                      0.2555
Root mean squared error                  0.3398
Relative absolute error                 80.0793 %
Root relative squared error             85.0774 %
Total Number of Instances               80     

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0.944     0.032      0.895     0.944     0.919      0.976    cc
                 0.375     0.094      0.5       0.375     0.429      0.782    g
                 0.889     0.097      0.727     0.889     0.8        0.926    h
                 0.929     0.106      0.65      0.929     0.765      0.939    r
                 0.357     0.03       0.714     0.357     0.476      0.845    ww
Weighted Avg.    0.713     0.072      0.704     0.713     0.69       0.897

=== Confusion Matrix ===

  a  b  c  d  e   <-- classified as
 17  0  1  0  0 |  a = cc
  2  6  1  7  0 |  b = g
  0  0 16  0  2 |  c = h
  0  1  0 13  0 |  d = r
  0  5  4  0  5 |  e = ww


============================ JStylo Analysis Output ============================
Started analysis on 2013-03-22, 17:42:59
Running 10-folds cross validation on training corpus

Training corpus:
> c (18 documents)
> d (13 documents)
> l (14 documents)
> o (15 documents)
> w (14 documents)

Feature set: 9 feature-set:
> Unique Words Count
> Complexity
> Sentence Count
> Average Sentence Length
> Average Syllables in Word
> Gunning-Fog Readability Index
> Character Space
> Letter Space
> Flesch Reading Ease Score

Classifiers used:
> weka.classifiers.functions.SMO                    	-C 1.0 -L 0.0010 -P 1.0E-12 -N 0 -V -1 -W 1 -K weka.classifiers.functions.supportVector.PolyKernel -C 250007 -E 1.0 

================================================================================

2013-03-22, 17:42:59 Extracting features from training corpus (using sparse representation)...
2013-03-22, 17:43:00 done!

Training corpus features (ARFF):
================================
@relation JStylo

@attribute 'Unique-Words-Count{-}' numeric
@attribute 'Complexity{-}' numeric
@attribute 'Sentence-Count{-}' numeric
@attribute 'Average-Sentence-Length{-}' numeric
@attribute 'Average-Syllables-in-Word{-}' numeric
@attribute 'Gunning-Fog-Readability-Index{-}' numeric
@attribute 'Character-Space{-}' numeric
@attribute 'Letter-Space{-}' numeric
@attribute 'Flesch-Reading-Ease-Score{-}' numeric
@attribute authorName {c,d,l,o,w}

@data
{0 216,1 0.432866,2 26,3 19.192308,4 2.062124,5 21.704979,6 3362,7 2784,8 12.899096}
{0 212,1 0.43002,2 23,3 21.434783,4 1.884381,5 17.661134,6 3167,7 2605,8 25.660034}
{0 229,1 0.452569,2 24,3 21.083333,4 1.727273,5 16.496574,6 3072,7 2499,8 39.308144}
{0 232,1 0.467742,2 20,3 24.8,4 1.800403,5 18.468387,6 3116,7 2540,8 29.348887}
{0 226,1 0.445759,2 22,3 23.045455,4 1.74359,5 16.949937,6 3084,7 2510,8 35.936171}
{0 217,1 0.449275,2 20,3 24.15,4 1.89648,5 19.266625,6 3144,7 2585,8 21.880514}
{0 196,1 0.406639,2 24,3 20.083333,4 1.887967,5 17.825864,6 3108,7 2569,8 26.728425}
{0 238,1 0.473161,2 22,3 22.863636,4 1.856859,5 19.165335,6 3187,7 2625,8 26.538151}
{0 212,1 0.446316,2 22,3 21.590909,4 1.941053,5 17.478469,6 3135,7 2591,8 20.707175}
{0 231,1 0.474333,2 25,3 19.48,4 1.850103,5 17.812534,6 3114,7 2565,8 30.544114}
{0 218,1 0.438632,2 28,3 17.75,4 1.573441,5 13.2167,6 2684,7 2109,8 55.705672}
{0 260,1 0.507813,2 21,3 24.380952,4 1.693359,5 16.393006,6 2932,7 2359,8 38.83013}
{0 241,1 0.490835,2 19,3 25.842105,4 1.741344,5 17.180019,6 2929,7 2384,8 33.287544}
{0 259,1 0.504873,2 19,3 27,4 1.842105,5 18.831189,6 3190,7 2610,8 23.587895}
{0 223,1 0.433852,2 25,3 20.56,4 1.706226,5 14.527502,6 3036,7 2461,8 41.619907}
{0 249,1 0.510246,2 27,3 18.074074,4 1.75,5 14.85258,6 2901,7 2351,8 40.439815}
{0 242,1 0.477318,2 21,3 24.142857,4 1.607495,5 14.627557,6 2848,7 2271,8 46.335917}
{0 257,1 0.505906,2 18,3 28.222222,4 1.753937,5 18.769204,6 3085,7 2519,8 29.806374}
{0 259,1 0.525355,2 20,3 24.65,4 1.827586,5 19.75858,6 3295,7 2469,8 27.201457,9 d}
{0 231,1 0.472393,2 24,3 20.375,4 1.766871,5 16.657157,6 3219,7 2379,8 36.677074,9 d}
{0 247,1 0.496982,2 22,3 22.590909,4 1.788732,5 18.694311,6 3265,7 2456,8 32.578467,9 d}
{0 286,1 0.594595,2 25,3 19.24,4 1.825364,5 17.84153,6 3378,7 2449,8 32.88062,9 d}
{0 279,1 0.563636,2 18,3 27.5,4 1.737374,5 19.242424,6 3300,7 2416,8 31.940682,9 d}
{0 278,1 0.567347,2 24,3 20.416667,4 1.810204,5 17.472789,6 3213,7 2417,8 32.968818,9 d}
{0 262,1 0.535787,2 15,3 32.6,4 1.574642,5 19.01137,6 2969,7 2175,8 40.531276,9 d}
{0 247,1 0.497984,2 18,3 27.555556,4 1.739919,5 19.086738,6 3203,7 2440,8 31.668934,9 d}
{0 273,1 0.558282,2 23,3 21.26087,4 1.707566,5 15.293714,6 3177,7 2278,8 40.795095,9 d}
{0 281,1 0.55315,2 17,3 29.882353,4 1.807087,5 20.535618,6 3481,7 2520,8 23.624884,9 d}
{0 275,1 0.541339,2 18,3 28.222222,4 1.777559,5 20.422747,6 3324,7 2491,8 27.807948,9 d}
{0 282,1 0.549708,2 22,3 23.318182,4 1.890838,5 19.229807,6 3495,7 2656,8 23.202133,9 d}
{0 272,1 0.530214,2 21,3 24.428571,4 1.826511,5 19.59599,6 3482,7 2594,8 27.517193,9 d}
{0 285,1 0.584016,2 15,3 32.533333,4 1.784836,5 21.128087,6 3070,7 2431,8 22.816536,9 l}
{0 284,1 0.618736,2 18,3 25.5,4 1.949891,5 21.703268,6 3043,7 2458,8 15.991716,9 l}
{0 302,1 0.62268,2 15,3 32.333333,4 1.874227,5 22.665292,6 3168,7 2528,8 15.457079,9 l}
{0 289,1 0.612288,2 18,3 26.222222,4 1.904661,5 21.336347,6 3131,7 2524,8 19.085122,9 l}
{0 279,1 0.580042,2 19,3 25.315789,4 1.66736,5 16.695962,6 2814,7 2244,8 40.080846,9 l}
{0 299,1 0.613963,2 23,3 21.173913,4 1.833676,5 17.997286,6 3141,7 2568,8 30.214525,9 l}
{0 271,1 0.56341,2 31,3 15.516129,4 1.694387,5 13.940339,6 2911,7 2276,8 47.741015,9 l}
{0 259,1 0.525355,2 26,3 18.961538,4 1.610548,5 13.101857,6 2918,7 2270,8 51.336706,9 l}
{0 291,1 0.612632,2 20,3 23.75,4 1.698947,5 16.405263,6 2924,7 2307,8 38.997803,9 l}
{0 282,1 0.579055,2 18,3 27.055556,4 1.691992,5 18.37869,6 2933,7 2320,8 36.231106,9 l}
{0 290,1 0.606695,2 17,3 28.117647,4 1.73431,5 19.61526,6 2871,7 2288,8 31.572994,9 l}
{0 282,1 0.574338,2 18,3 27.277778,4 1.647658,5 17.591356,6 2883,7 2249,8 39.756202,9 l}
{0 285,1 0.603814,2 19,3 24.842105,4 1.794492,5 18.157181,6 3041,7 2351,8 29.80628,9 l}
{0 272,1 0.570231,2 13,3 36.692308,4 1.716981,5 21.888663,6 2907,7 2294,8 24.335704,9 l}
{0 285,1 0.585216,2 24,3 20.291667,4 1.511294,5 12.716256,6 2919,7 2042,8 58.383517,9 o}
{0 292,1 0.58871,2 21,3 23.619048,4 1.768145,5 17.996006,6 3152,7 2394,8 33.276586,9 o}
{0 228,1 0.466258,2 12,3 40.75,4 1.842536,5 26.115951,6 3088,7 2469,8 9.595222,9 o}
{0 274,1 0.572025,2 14,3 34.214286,4 1.820459,5 23.12204,6 3194,7 2407,8 18.096644,9 o}
{0 294,1 0.602459,2 17,3 28.705882,4 1.538934,5 15.99055,6 2984,7 2106,8 47.504677,9 o}
{0 253,1 0.522727,2 19,3 25.473684,4 1.840909,5 20.106829,6 3015,7 2445,8 25.238301,9 o}
{0 234,1 0.468938,2 20,3 24.95,4 1.945892,5 20.881804,6 3323,7 2714,8 16.888305,9 o}
{0 281,1 0.578189,2 17,3 28.588235,4 1.90535,5 21.805664,6 3132,7 2523,8 16.625349,9 o}
{0 272,1 0.552846,2 21,3 23.428571,4 1.977642,5 20.590941,6 3322,7 2686,8 15.746463,9 o}
{0 283,1 0.561508,2 17,3 29.647059,4 2.031746,5 23.128665,6 3404,7 2752,8 4.857521,9 o}
{0 291,1 0.584337,2 15,3 33.2,4 1.797189,5 23.320161,6 3280,7 2502,8 21.094831,9 o}
{0 268,1 0.553719,2 18,3 26.888889,4 1.657025,5 17.284481,6 2937,7 2291,8 39.35848,9 o}
{0 279,1 0.553571,2 16,3 31.5,4 1.759921,5 20.139683,6 3140,7 2487,8 25.973214,9 o}
{0 277,1 0.558468,2 16,3 31,4 1.747984,5 20.383871,6 3084,7 2443,8 27.490565,9 o}
{0 273,1 0.547094,2 11,3 45.363636,4 1.54509,5 23.035234,6 3045,7 2221,8 30.07628,9 o}
{0 260,1 0.527383,2 17,3 29,4 1.969574,5 22.87789,6 3402,7 2718,8 10.774037,9 w}
{0 275,1 0.563525,2 12,3 40.666667,4 1.977459,5 27.33224,6 3371,7 2738,8 -1.734699,9 w}
{0 260,1 0.516899,2 28,3 17.964286,4 1.66004,5 14.183726,6 2986,7 2375,8 48.161886,9 w}
{0 248,1 0.50924,2 28,3 17.392857,4 1.718686,5 15.170695,6 2982,7 2402,8 43.780429,9 w}
{0 241,1 0.503132,2 20,3 23.95,4 1.822547,5 19.016326,6 3043,7 2457,8 28.338276,9 w}
{0 218,1 0.453222,2 19,3 25.315789,4 1.852391,5 18.941285,6 3116,7 2544,8 24.427208,9 w}
{0 220,1 0.449898,2 26,3 18.807692,4 1.871166,5 17.175429,6 3192,7 2598,8 29.444579,9 w}
{0 251,1 0.50503,2 21,3 23.666667,4 1.794769,5 18.561234,6 3114,7 2528,8 30.975909,9 w}
{0 241,1 0.502083,2 19,3 25.263158,4 1.802083,5 19.355263,6 2968,7 2386,8 28.736645,9 w}
{0 261,1 0.529412,2 18,3 27.388889,4 1.713996,5 17.852107,6 2876,7 2273,8 34.031221,9 w}
{0 264,1 0.547718,2 17,3 28.352941,4 1.688797,5 18.146156,6 2860,7 2259,8 35.184566,9 w}
{0 239,1 0.498956,2 18,3 26.611111,4 1.659708,5 17.325029,6 2932,7 2293,8 39.413449,9 w}

Calculating InfoGain on the training set's features
===================================================
Features InfoGain score (non-zero only):
----------------------------------------
> Complexity{-}                      0.781525
> Unique-Words-Count{-}              0.532661
> Character-Space{-}                 0.344105

Feature-type breakdown:
-----------------------
> Letter-Space                    0.000000 (0.00%)
> Sentence-Count                  0.000000 (0.00%)
> Unique-Words-Count              0.532661 (32.12%)
> Average-Syllables-in-Word       0.000000 (0.00%)
> Complexity                      0.781525 (47.13%)
> Gunning-Fog-Readability-Index   0.000000 (0.00%)
> Average-Sentence-Length         0.000000 (0.00%)
> Flesch-Reading-Ease-Score       0.000000 (0.00%)
> Character-Space                 0.344105 (20.75%)

done!

2013-03-22, 17:43:00 Starting 10-folds cross-validation on training corpus phase...

================================================================================

Running analysis with classifier 1 out of 1:
> Classifier: weka.classifiers.functions.SMO
> Options:    -C 1.0 -L 0.0010 -P 1.0E-12 -N 0 -V -1 -W 1 -K weka.classifiers.functions.supportVector.PolyKernel -C 250007 -E 1.0 

2013-03-22, 17:43:00 Starting cross validation...
2013-03-22, 17:43:01 done!

=== Summary ===

Correctly Classified Instances          40               55.5556 %
Incorrectly Classified Instances        32               44.4444 %
Kappa statistic                          0.4315
Mean absolute error                      0.27  
Root mean squared error                  0.3602
Relative absolute error                 84.7802 %
Root relative squared error             90.2918 %
Total Number of Instances               72     

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0.889     0.259      0.533     0.889     0.667      0.866    c
                 0.538     0.017      0.875     0.538     0.667      0.863    d
                 0.714     0.121      0.588     0.714     0.645      0.883    l
                 0.467     0.14       0.467     0.467     0.467      0.714    o
                 0         0.033      0         0         0          0.604    w
Weighted Avg.    0.556     0.126      0.503     0.556     0.51       0.794

=== Confusion Matrix ===

  a  b  c  d  e   <-- classified as
 16  0  0  1  1 |  a = c
  3  7  1  2  0 |  b = d
  1  0 10  3  0 |  c = l
  2  1  4  7  1 |  d = o
  8  0  2  2  0 |  e = w

